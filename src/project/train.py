# src/project/train.py
import torch
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import EMNIST
import matplotlib.pyplot as plt

import time
from pathlib import Path
import multiprocessing
from PIL import Image
from torchvision.transforms import functional as TF

from project.model import CNN  # —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ src –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ Sources Root

class Config:
    batch_size = 64
    epochs = 20
    learning_rate = 0.001
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    EMNIST_SPLIT = "balanced"
    # –ü–æ–ø—Ä–∞–≤–ª—è—Ç—å –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é EMNIST (–æ–±—ã—á–Ω–æ –Ω—É–∂–Ω–æ): True/False
    EMNIST_ORIENTATION_FIX = True
    # –ù–µ–±–æ–ª—å—à–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è (RandomAffine) ‚Äî –≤–∫–ª—é—á–∏, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –ø–æ–≤—ã—Å–∏—Ç—å —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å
    USE_AUGMENTATION = False
    # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞: "adam" –∏–ª–∏ "sgd"
    OPTIMIZER = "adam"
    # Scheduler (StepLR) –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    SCHEDULER_STEP = 10
    SCHEDULER_GAMMA = 0.1

    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    print(f"EMNIST split: {EMNIST_SPLIT}, orientation_fix={EMNIST_ORIENTATION_FIX}, augmentation={USE_AUGMENTATION}")
    print(f"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {OPTIMIZER}")

# –≤—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (src/project -> –∫–æ—Ä–µ–Ω—å)
BASE_DIR = Path(__file__).resolve().parents[2]

DATA_DIR = BASE_DIR / "data"
MODEL_DIR = BASE_DIR / "models"
GRAPHICS_DIR = BASE_DIR / "graphics"

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
DATA_DIR.mkdir(parents=True, exist_ok=True)
MODEL_DIR.mkdir(parents=True, exist_ok=True)
GRAPHICS_DIR.mkdir(parents=True, exist_ok=True)

# –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–±–æ—Ä num_workers
_cpu_count = multiprocessing.cpu_count() if hasattr(multiprocessing, "cpu_count") else 1
NUM_WORKERS = min(2, max(0, _cpu_count - 1))  # 0..2

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def emnist_orientation_fix_pil(img: Image.Image) -> Image.Image:
    """
    –ù–∞–¥—ë–∂–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è EMNIST, —Ä–∞–±–æ—Ç–∞—é—â–∞—è —Å PIL Image.
    –û–±—ã—á–Ω–æ rotate(-90) + hflip –¥–∞—ë—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—É—é –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é.
    –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω ‚Äî –ø–æ–ø—Ä–æ–±—É–π –ø–æ–º–µ–Ω—è—Ç—å rotate —É–≥–æ–ª –∏–ª–∏ —É–±—Ä–∞—Ç—å hflip.
    """
    # –ü–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º -90 –≥—Ä–∞–¥—É—Å–æ–≤ –∏ –∑–µ—Ä–∫–∞–ª–∏–º –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏
    img = TF.rotate(img, -90, expand=True)
    img = TF.hflip(img)
    return img


# DataLoaders (EMNIST)
def get_data_loaders():
    # –°–æ–±–∏—Ä–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    transforms_list = []

    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞, –¥–µ–ª–∞–µ–º —ç—Ç–æ —Å PIL
    if Config.EMNIST_ORIENTATION_FIX:
        transforms_list.append(transforms.Lambda(lambda img: emnist_orientation_fix_pil(img)))

    # –ù–µ–±–æ–ª—å—à–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if Config.USE_AUGMENTATION:
        aug = transforms.RandomAffine(degrees=8, translate=(0.06, 0.06))
        transforms_list.append(transforms.RandomApply([aug], p=0.5))

    # –ü–µ—Ä–µ–≤–æ–¥ –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–∞ –∂–µ, —á—Ç–æ —É MNIST)
    transforms_list.extend([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    transform = transforms.Compose(transforms_list)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º EMNIST
    train_dataset = EMNIST(
        root=str(DATA_DIR),
        split=Config.EMNIST_SPLIT,
        train=True,
        download=True,
        transform=transform
    )

    test_dataset = EMNIST(
        root=str(DATA_DIR),
        split=Config.EMNIST_SPLIT,
        train=False,
        download=True,
        transform=transform
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=Config.batch_size,
        shuffle=True,
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=Config.batch_size,
        shuffle=False,
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )

    # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
    try:
        n_classes = len(train_dataset.classes)
    except Exception:
        split_to_classes = {"byclass": 62, "balanced": 47, "bymerge": 47, "letters": 26, "digits": 10, "mnist": 10}
        n_classes = split_to_classes.get(Config.EMNIST_SPLIT, 47)

    return train_loader, test_loader, n_classes

# Train / Test
def train_epoch(model, device, train_loader, optimizer, epoch):
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)

        if batch_idx % 100 == 0:
            processed = batch_idx * len(data)
            percent = 100. * batch_idx / len(train_loader)
            print(f'Train Epoch: {epoch} [{processed}/{len(train_loader.dataset)} '
                  f'({percent:.0f}%)]\tLoss: {loss.item():.6f}')

    avg_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0.0
    accuracy = 100. * correct / total if total > 0 else 0.0
    return avg_loss, accuracy


def test(model, device, test_loader):
    model.eval()
    test_loss = 0.0
    correct = 0

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    n_samples = len(test_loader.dataset)
    test_loss_avg = test_loss / n_samples if n_samples > 0 else 0.0
    accuracy = 100. * correct / n_samples if n_samples > 0 else 0.0

    print(f'\nTest set: Average loss: {test_loss_avg:.4f}, '
          f'Accuracy: {correct}/{n_samples} ({accuracy:.2f}%)\n')
    return test_loss_avg, accuracy

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤
def visualize_samples(test_loader, model, device, num_samples=10):
    model.eval()
    data_iter = iter(test_loader)
    images, labels = next(data_iter)
    images, labels = images.to(device), labels.to(device)

    with torch.no_grad():
        outputs = model(images[:num_samples])
        preds = outputs.argmax(dim=1)

    images_np = images.cpu().numpy()
    labels_np = labels.cpu().numpy()
    preds_np = preds.cpu().numpy()

    fig, axes = plt.subplots(2, 5, figsize=(12, 6))
    for i, ax in enumerate(axes.flat):
        ax.imshow(images_np[i][0], cmap='gray')
        ax.set_title(f'True: {labels_np[i]}, Pred: {preds_np[i]}')
        ax.axis('off')

    plt.tight_layout()
    out_path = GRAPHICS_DIR / "emnist_predictions.png"
    plt.savefig(str(out_path), dpi=150, bbox_inches='tight')
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {out_path}")
    plt.close()

def main():
    cfg = Config()

    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö EMNIST...")
    train_loader, test_loader, n_classes = get_data_loaders()

    print(f"–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(train_loader.dataset)}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(test_loader.dataset)}")
    print(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {cfg.batch_size}")
    print(f"–ß–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤ (–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞): {n_classes}")

    device = cfg.device

    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å —Å –Ω—É–∂–Ω—ã–º —á–∏—Å–ª–æ–º –≤—ã—Ö–æ–¥–æ–≤
    model = CNN(num_classes=n_classes).to(device)
    print(f"\n–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {model.__class__.__name__}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in model.parameters()):,}")

    # –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    if Config.OPTIMIZER.lower() == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
    else:
        optimizer = optim.Adam(model.parameters(), lr=cfg.learning_rate, weight_decay=1e-5)

    # Scheduler
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=Config.SCHEDULER_STEP, gamma=Config.SCHEDULER_GAMMA)

    train_losses = []
    train_accuracies = []
    test_losses = []
    test_accuracies = []

    best_acc = 0.0
    best_checkpoint = MODEL_DIR / "best_emnist_cnn.pth"

    print("\n–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    start_time = time.time()

    for epoch in range(1, cfg.epochs + 1):
        epoch_start = time.time()

        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, epoch)

        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        test_loss, test_acc = test(model, device, test_loader)

        # Scheduler step (–ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)
        scheduler.step()

        epoch_time = time.time() - epoch_start

        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        test_losses.append(test_loss)
        test_accuracies.append(test_acc)

        print(f"–≠–ø–æ—Ö–∞ {epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {epoch_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {train_acc:.2f}%")
        print(f"–¢–µ—Å—Ç–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {test_acc:.2f}%\n")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–π —á–µ–∫–ø–æ–π–Ω—Ç
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'train_losses': train_losses,
                'test_losses': test_losses,
                'train_accuracies': train_accuracies,
                'test_accuracies': test_accuracies,
                'config': {
                    'batch_size': cfg.batch_size,
                    'epochs': cfg.epochs,
                    'learning_rate': cfg.learning_rate,
                    'emnist_split': cfg.EMNIST_SPLIT
                }
            }, str(best_checkpoint))
            print(f"–ù–æ–≤—ã–π –ª—É—á—à–∏–π —á–µ–∫–ø–æ–π–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {best_checkpoint} (acc={best_acc:.2f}%)")

    total_time = time.time() - start_time
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")

    # –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–∏
    print("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤...")
    visualize_samples(test_loader, model, device)

    # –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(test_losses, label='Test Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss during Training')

    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label='Train Accuracy')
    plt.plot(test_accuracies, label='Test Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.title('Accuracy during Training')

    plt.tight_layout()
    history_path = GRAPHICS_DIR / "training_history.png"
    plt.savefig(str(history_path), dpi=150, bbox_inches='tight')
    print(f"–°–æ—Ö—Ä–∞–Ω—ë–Ω –≥—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è: {history_path}")
    plt.close()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫ –≤ models/
    final_save = MODEL_DIR / "emnist_cnn_model_final.pth"
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_losses': train_losses,
        'test_losses': test_losses,
        'train_accuracies': train_accuracies,
        'test_accuracies': test_accuracies,
        'config': {
            'batch_size': cfg.batch_size,
            'epochs': cfg.epochs,
            'learning_rate': cfg.learning_rate,
            'emnist_split': cfg.EMNIST_SPLIT
        }
    }, str(final_save))

    print(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ '{final_save}'")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if test_accuracies:
        best_test_acc = max(test_accuracies)
        best_epoch = test_accuracies.index(best_test_acc) + 1
        print(f"\nüèÜ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {best_test_acc:.2f}% –Ω–∞ —ç–ø–æ—Ö–µ {best_epoch}")


# -----------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
# -----------------------
def load_and_test_model():
    cfg = Config()

    _, test_loader, n_classes = get_data_loaders()
    device = cfg.device

    model = CNN(num_classes=n_classes).to(device)
    save_path = MODEL_DIR / "best_emnist_cnn.pth"

    if not save_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {save_path}")

    checkpoint = torch.load(str(save_path), map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])

    print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    test_loss, test_accuracy = test(model, device, test_loader)

    return test_accuracy


if __name__ == '__main__':
    main()

    # –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å:
    load_and_test_model()
